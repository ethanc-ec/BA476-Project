{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the supplementary data from Kaggle for artist info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Lead Streams</th>\n",
       "      <th>Feats</th>\n",
       "      <th>Tracks</th>\n",
       "      <th>One Billion</th>\n",
       "      <th>100 Million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>50162292808</td>\n",
       "      <td>19246513666</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>44369032140</td>\n",
       "      <td>5391990975</td>\n",
       "      <td>163</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>38153682361</td>\n",
       "      <td>2791278201</td>\n",
       "      <td>240</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>34767779741</td>\n",
       "      <td>4288903657</td>\n",
       "      <td>186</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>32596728109</td>\n",
       "      <td>424053296</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Artist Name  Lead Streams        Feats  Tracks  One Billion  100 Million\n",
       "0         Drake   50162292808  19246513666     262            6          130\n",
       "1     Bad Bunny   44369032140   5391990975     163            5          118\n",
       "2    Ed Sheeran   38153682361   2791278201     240           10           62\n",
       "3    The Weeknd   34767779741   4288903657     186            8           72\n",
       "4  Taylor Swift   32596728109    424053296     323            1           96"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if Path(\"data/spotify_artist_data.csv\").exists():\n",
    "    artist_stats = pd.read_csv(\"data/spotify_artist_data.csv\")\n",
    "else:\n",
    "    path = kagglehub.dataset_download(\"adnananam/spotify-artist-stats\")\n",
    "    artist_stats = pd.read_csv(path + \"/spotify_artist_data.csv\", index_col=0)\n",
    "\n",
    "    # Remove error rows b/c the creator didn't process correctly\n",
    "    artist_stats = artist_stats[artist_stats[\"Lead Streams\"] != \"Lead Streams\"]\n",
    "\n",
    "    # Cast numeric columns to int\n",
    "    for col in [\"Lead Streams\", \"Feats\", \"Tracks\", \"One Billion\", \"100 Million\"]:\n",
    "        artist_stats[col] = artist_stats[col].str.replace(\",\", \"\").astype(int)\n",
    "\n",
    "    # Remove the last updated column, it's not useful/relevant\n",
    "    artist_stats = artist_stats.drop(columns=[\"Last Updated\"])\n",
    "\n",
    "    artist_stats.to_csv(\"data/spotify_artist_data.csv\", index=False)\n",
    "\n",
    "artist_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from HuggingFace using Pandas, and drop the extra index column. The `na`/`NaN` values were dropped from the `artists` column because that column is used to merge the supplementary data above with the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>duration_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>230.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>149.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>210.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>201.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>198.853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                 artists  \\\n",
       "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  explicit  danceability  energy  \\\n",
       "0                      Comedy          73     False         0.676  0.4610   \n",
       "1            Ghost - Acoustic          55     False         0.420  0.1660   \n",
       "2              To Begin Again          57     False         0.438  0.3590   \n",
       "3  Can't Help Falling In Love          71     False         0.266  0.0596   \n",
       "4                     Hold On          82     False         0.618  0.4430   \n",
       "\n",
       "   key  loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0    1    -6.746     0       0.1430        0.0322          0.000001    0.3580   \n",
       "1    1   -17.235     1       0.0763        0.9240          0.000006    0.1010   \n",
       "2    0    -9.734     1       0.0557        0.2100          0.000000    0.1170   \n",
       "3    0   -18.515     1       0.0363        0.9050          0.000071    0.1320   \n",
       "4    2    -9.681     1       0.0526        0.4690          0.000000    0.0829   \n",
       "\n",
       "   valence    tempo  time_signature track_genre  duration_s  \n",
       "0    0.715   87.917               4    acoustic     230.666  \n",
       "1    0.267   77.489               4    acoustic     149.610  \n",
       "2    0.120   76.332               4    acoustic     210.826  \n",
       "3    0.143  181.740               3    acoustic     201.933  \n",
       "4    0.167  119.949               4    acoustic     198.853  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulled dataset from HF, dropped unneeded index column\n",
    "if Path(\"data/spotify_tracks.csv\").exists():\n",
    "    df = pd.read_csv(\"data/spotify_tracks.csv\")\n",
    "else:\n",
    "    df = (\n",
    "        pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")\n",
    "        .drop(\"Unnamed: 0\", axis=1)\n",
    "        .dropna(subset=[\"artists\"])\n",
    "    )\n",
    "\n",
    "    df[\"duration_s\"] = df[\"duration_ms\"] / 1000\n",
    "    df = df.drop(columns=[\"duration_ms\"])  # Drop original duration column, keep seconds\n",
    "\n",
    "    df.to_csv(\"data/spotify_tracks.csv\", index=False)\n",
    "\n",
    "df_nodupe = df.drop_duplicates(subset=[\"track_id\"]).copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in more information to the main dataset using each artist's stats. If there are two or more artists present, the stats are averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"data/spotify_tracks_processed.csv\").exists():\n",
    "    art_stats_name = set(artist_stats[\"Artist Name\"].values)\n",
    "    lead_streams, feats, tracks, one_billion, hundred_million = [], [], [], [], []\n",
    "\n",
    "    for row in tqdm(df_nodupe.iterrows(), total=df_nodupe.shape[0], desc=\"Processing rows\"):\n",
    "        artists = [x.strip() for x in row[1][\"artists\"].split(\";\")]\n",
    "        temp_lead_streams, temp_feats, temp_tracks, temp_one_billion, temp_hundred_million = (\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "        )\n",
    "\n",
    "        for artist in artists:\n",
    "            if artist in art_stats_name:\n",
    "                temp_lead_streams.append(\n",
    "                    artist_stats[artist_stats[\"Artist Name\"] == artist][\"Lead Streams\"].values[0]\n",
    "                )\n",
    "                temp_feats.append(artist_stats[artist_stats[\"Artist Name\"] == artist][\"Feats\"].values[0])\n",
    "                temp_tracks.append(\n",
    "                    artist_stats[artist_stats[\"Artist Name\"] == artist][\"Tracks\"].values[0]\n",
    "                )\n",
    "                temp_one_billion.append(\n",
    "                    artist_stats[artist_stats[\"Artist Name\"] == artist][\"One Billion\"].values[0]\n",
    "                )\n",
    "                temp_hundred_million.append(\n",
    "                    artist_stats[artist_stats[\"Artist Name\"] == artist][\"100 Million\"].values[0]\n",
    "                )\n",
    "\n",
    "        for col, temp in zip(\n",
    "            [lead_streams, feats, tracks, one_billion, hundred_million],\n",
    "            [temp_lead_streams, temp_feats, temp_tracks, temp_one_billion, temp_hundred_million],\n",
    "            strict=True,\n",
    "        ):\n",
    "            if len(temp) > 0:\n",
    "                col.append(np.mean(temp))\n",
    "            else:\n",
    "                col.append(0)\n",
    "\n",
    "    df_nodupe[\"lead_streams\"] = lead_streams\n",
    "    df_nodupe[\"feats\"] = feats\n",
    "    df_nodupe[\"tracks\"] = tracks\n",
    "    df_nodupe[\"one_billion\"] = one_billion\n",
    "    df_nodupe[\"hundred_million\"] = hundred_million\n",
    "\n",
    "    g_dummy = pd.get_dummies(df[\"track_genre\"]).groupby(df[\"track_id\"]).sum().astype(int).reset_index()\n",
    "\n",
    "    dummy_val = g_dummy.copy()\n",
    "    dummy_val[\"total\"] = dummy_val.sum(axis=1, numeric_only=True)\n",
    "    dummy_val = dummy_val[[\"track_id\", \"total\"]].sort_values(\"track_id\", ascending=True)\n",
    "\n",
    "    process_check = (\n",
    "        df.groupby(\"track_id\")\n",
    "        .size()\n",
    "        .to_frame(\"total\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"track_id\", ascending=True)\n",
    "    )\n",
    "\n",
    "    for df1, df2 in zip(process_check.iterrows(), dummy_val.iterrows(), strict=True):\n",
    "        assert (df1[1][\"total\"] == df2[1][\"total\"]) and (df1[1][\"track_id\"] == df2[1][\"track_id\"])\n",
    "\n",
    "    df = df_nodupe.merge(g_dummy, on=\"track_id\").drop(\n",
    "        [\"track_id\", \"artists\", \"album_name\", \"track_name\", \"track_genre\"], axis=1\n",
    "    )\n",
    "    df[\"explicit\"] = df[\"explicit\"].astype(int)\n",
    "    df.to_csv(\"data/spotify_tracks_processed.csv\", index=False)\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv(\"data/spotify_tracks_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.34835154909974264\n",
      "MSE: 274.2463457682768\n",
      "RMSE: 16.56038483152722\n",
      "MAE: 11.862547512613704\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[df.columns.difference([\"popularity\"])]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "model = LinearRegression(\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>spanish</th>\n",
       "      <th>study</th>\n",
       "      <th>swedish</th>\n",
       "      <th>synth-pop</th>\n",
       "      <th>tango</th>\n",
       "      <th>techno</th>\n",
       "      <th>trance</th>\n",
       "      <th>trip-hop</th>\n",
       "      <th>turkish</th>\n",
       "      <th>world-music</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "      <td>89740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.198808</td>\n",
       "      <td>0.085848</td>\n",
       "      <td>0.562166</td>\n",
       "      <td>0.634458</td>\n",
       "      <td>5.283530</td>\n",
       "      <td>-8.498994</td>\n",
       "      <td>0.636973</td>\n",
       "      <td>0.087442</td>\n",
       "      <td>0.328285</td>\n",
       "      <td>0.173415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.011143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.580640</td>\n",
       "      <td>0.280141</td>\n",
       "      <td>0.176692</td>\n",
       "      <td>0.256606</td>\n",
       "      <td>3.559912</td>\n",
       "      <td>5.221518</td>\n",
       "      <td>0.480875</td>\n",
       "      <td>0.113278</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.323849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.105185</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.104973</td>\n",
       "      <td>0.105079</td>\n",
       "      <td>0.105291</td>\n",
       "      <td>0.105079</td>\n",
       "      <td>0.105079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.531000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-10.322250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-7.185000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-5.108000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.097625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.532000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         popularity      explicit  danceability        energy           key  \\\n",
       "count  89740.000000  89740.000000  89740.000000  89740.000000  89740.000000   \n",
       "mean      33.198808      0.085848      0.562166      0.634458      5.283530   \n",
       "std       20.580640      0.280141      0.176692      0.256606      3.559912   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       19.000000      0.000000      0.450000      0.457000      2.000000   \n",
       "50%       33.000000      0.000000      0.576000      0.676000      5.000000   \n",
       "75%       49.000000      0.000000      0.692000      0.853000      8.000000   \n",
       "max      100.000000      1.000000      0.985000      1.000000     11.000000   \n",
       "\n",
       "           loudness          mode   speechiness  acousticness  \\\n",
       "count  89740.000000  89740.000000  89740.000000  89740.000000   \n",
       "mean      -8.498994      0.636973      0.087442      0.328285   \n",
       "std        5.221518      0.480875      0.113278      0.338321   \n",
       "min      -49.531000      0.000000      0.000000      0.000000   \n",
       "25%      -10.322250      0.000000      0.036000      0.017100   \n",
       "50%       -7.185000      1.000000      0.048900      0.188000   \n",
       "75%       -5.108000      1.000000      0.085900      0.625000   \n",
       "max        4.532000      1.000000      0.965000      0.996000   \n",
       "\n",
       "       instrumentalness  ...       spanish         study       swedish  \\\n",
       "count      89740.000000  ...  89740.000000  89740.000000  89740.000000   \n",
       "mean           0.173415  ...      0.011143      0.011143      0.011143   \n",
       "std            0.323849  ...      0.104973      0.105185      0.104973   \n",
       "min            0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%            0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%            0.000058  ...      0.000000      0.000000      0.000000   \n",
       "75%            0.097625  ...      0.000000      0.000000      0.000000   \n",
       "max            1.000000  ...      1.000000      2.000000      1.000000   \n",
       "\n",
       "          synth-pop         tango        techno        trance      trip-hop  \\\n",
       "count  89740.000000  89740.000000  89740.000000  89740.000000  89740.000000   \n",
       "mean       0.011143      0.011143      0.011143      0.011143      0.011143   \n",
       "std        0.104973      0.104973      0.104973      0.105079      0.105291   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      2.000000      2.000000   \n",
       "\n",
       "            turkish   world-music  \n",
       "count  89740.000000  89740.000000  \n",
       "mean       0.011143      0.011143  \n",
       "std        0.105079      0.105079  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        2.000000      2.000000  \n",
       "\n",
       "[8 rows x 134 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity          1.000000\n",
       "pop-film            0.134407\n",
       "k-pop               0.122339\n",
       "hundred_million     0.106079\n",
       "chill               0.105386\n",
       "                      ...   \n",
       "detroit-techno     -0.113376\n",
       "latin              -0.127165\n",
       "instrumentalness   -0.127477\n",
       "romance            -0.141027\n",
       "iranian            -0.157936\n",
       "Name: popularity, Length: 134, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[\"popularity\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backfill missing `lead_streams` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros in lead_streams: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Create mask for rows where lead_streams is 0\n",
    "mask = df['lead_streams'] == 0\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X_train = df[~mask].drop(['lead_streams', 'popularity'], axis=1)\n",
    "y_train = df[~mask]['lead_streams']\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_pred = df[mask].drop(['lead_streams', 'popularity'], axis=1)\n",
    "\n",
    "# Initialize and train the RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200, \n",
    "    random_state=42, \n",
    "    n_jobs=-1, \n",
    "    max_features='sqrt',\n",
    "    verbose=1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for empty values\n",
    "predictions = rf_model.predict(X_pred)\n",
    "\n",
    "# Fill in the empty values\n",
    "df.loc[mask, 'lead_streams'] = predictions\n",
    "\n",
    "# Verify no more zeros in lead_streams\n",
    "print(f\"Number of zeros in lead_streams: {(df['lead_streams'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add clusters as additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>study</th>\n",
       "      <th>swedish</th>\n",
       "      <th>synth-pop</th>\n",
       "      <th>tango</th>\n",
       "      <th>techno</th>\n",
       "      <th>trance</th>\n",
       "      <th>trip-hop</th>\n",
       "      <th>turkish</th>\n",
       "      <th>world-music</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89735</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>5</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89736</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89737</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89738</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89739</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89740 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity  explicit  danceability  energy  key  loudness  mode  \\\n",
       "0              73         0         0.676  0.4610    1    -6.746     0   \n",
       "1              55         0         0.420  0.1660    1   -17.235     1   \n",
       "2              57         0         0.438  0.3590    0    -9.734     1   \n",
       "3              71         0         0.266  0.0596    0   -18.515     1   \n",
       "4              82         0         0.618  0.4430    2    -9.681     1   \n",
       "...           ...       ...           ...     ...  ...       ...   ...   \n",
       "89735          21         0         0.172  0.2350    5   -16.393     1   \n",
       "89736          22         0         0.174  0.1170    0   -18.318     0   \n",
       "89737          22         0         0.629  0.3290    0   -10.895     0   \n",
       "89738          41         0         0.587  0.5060    7   -10.889     1   \n",
       "89739          22         0         0.526  0.4870    1   -10.204     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  ...  study  swedish  \\\n",
       "0           0.1430        0.0322          0.000001  ...      0        0   \n",
       "1           0.0763        0.9240          0.000006  ...      0        0   \n",
       "2           0.0557        0.2100          0.000000  ...      0        0   \n",
       "3           0.0363        0.9050          0.000071  ...      0        0   \n",
       "4           0.0526        0.4690          0.000000  ...      0        0   \n",
       "...            ...           ...               ...  ...    ...      ...   \n",
       "89735       0.0422        0.6400          0.928000  ...      0        0   \n",
       "89736       0.0401        0.9940          0.976000  ...      0        0   \n",
       "89737       0.0420        0.8670          0.000000  ...      0        0   \n",
       "89738       0.0297        0.3810          0.000000  ...      0        0   \n",
       "89739       0.0725        0.6810          0.000000  ...      0        0   \n",
       "\n",
       "       synth-pop  tango  techno  trance  trip-hop  turkish  world-music  \\\n",
       "0              0      0       0       0         0        0            0   \n",
       "1              0      0       0       0         0        0            0   \n",
       "2              0      0       0       0         0        0            0   \n",
       "3              0      0       0       0         0        0            0   \n",
       "4              0      0       0       0         0        0            0   \n",
       "...          ...    ...     ...     ...       ...      ...          ...   \n",
       "89735          0      0       0       0         0        0            1   \n",
       "89736          0      0       0       0         0        0            1   \n",
       "89737          0      0       0       0         0        0            1   \n",
       "89738          0      0       0       0         0        0            1   \n",
       "89739          0      0       0       0         0        0            1   \n",
       "\n",
       "       cluster  \n",
       "0           12  \n",
       "1           16  \n",
       "2           12  \n",
       "3           12  \n",
       "4           12  \n",
       "...        ...  \n",
       "89735       12  \n",
       "89736       19  \n",
       "89737       12  \n",
       "89738       12  \n",
       "89739       12  \n",
       "\n",
       "[89740 rows x 135 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_df = StandardScaler().fit_transform(df[df.columns.difference([\"popularity\"])])\n",
    "kmeans = KMeans(n_clusters=40, random_state=42)\n",
    "kmeans.fit(std_df)\n",
    "df[\"cluster\"] = kmeans.labels_\n",
    "df[\"cluster\"] = df[\"cluster\"].astype(\"category\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual correlation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations > |0.50|:\n",
      "             var1             var2      corr\n",
      "singer-songwriter       songwriter  1.000000\n",
      "     lead_streams  hundred_million  0.952045\n",
      "     lead_streams      one_billion  0.822557\n",
      "           reggae        reggaeton  0.801791\n",
      "           energy         loudness  0.758774\n",
      "           latino        reggaeton  0.736928\n",
      "           energy     acousticness -0.732569\n",
      "              dub          dubstep  0.723472\n",
      "      one_billion  hundred_million  0.706854\n",
      "             punk        punk-rock  0.624188\n",
      "      speechiness           comedy  0.623655\n",
      "              edm            house  0.619816\n",
      "           latino           reggae  0.614418\n",
      "     lead_streams featured_streams  0.612210\n",
      " featured_streams  hundred_million  0.593427\n",
      "            latin           latino  0.590402\n",
      "         alt-rock      alternative  0.588235\n",
      "  featured_tracks        classical  0.583836\n",
      "         loudness     acousticness -0.582664\n",
      "            indie        indie-pop  0.573530\n",
      " featured_streams      one_billion  0.528161\n",
      "            latin           reggae  0.509465\n",
      "            latin        reggaeton  0.509465\n"
     ]
    }
   ],
   "source": [
    "dfc = df.corr()\n",
    "\n",
    "# Create mask for correlations > abs(0.50)\n",
    "mask = np.abs(dfc) > 0.50\n",
    "\n",
    "# Get upper triangle of mask to avoid duplicates\n",
    "mask_upper = np.triu(mask, k=1)\n",
    "\n",
    "# Find correlation pairs exceeding threshold\n",
    "high_corr = []\n",
    "for i in range(len(dfc.columns)):\n",
    "    for j in range(i + 1, len(dfc.columns)):\n",
    "        if mask_upper[i, j]:\n",
    "            high_corr.append({\"var1\": dfc.columns[i], \"var2\": dfc.columns[j], \"corr\": dfc.iloc[i, j]})\n",
    "\n",
    "# Convert to dataframe and sort by absolute correlation\n",
    "high_corr_df = pd.DataFrame(high_corr)\n",
    "high_corr_df = high_corr_df.sort_values(\"corr\", key=abs, ascending=False)\n",
    "\n",
    "print(\"Correlations > |0.50|:\")\n",
    "print(high_corr_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop highly correlated columns\n",
    "\n",
    "- `singer-songwriter`\n",
    "  - Removed since it is an identical match to `songwriter`\n",
    "- `hundred_million`, `one_billion`, and `featured_streams`\n",
    "  - High correlation to `lead_streams`, which was from the same dataset and all columns were used during backfilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"singer-songwriter\", \"hundred_million\", \"one_billion\", \"featured_streams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.3474713146844247\n",
      "MSE: 274.616792550567\n",
      "RMSE: 16.571565784516775\n",
      "MAE: 11.881378178125107\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[df.columns.difference([\"popularity\"])]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "model = LinearRegression(\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.5559460661296558\n",
      "MSE: 185.71911270467845\n",
      "RMSE: 13.627879978363415\n",
      "MAE: 9.219101136800697\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[df.columns.difference([\"popularity\"])]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200, random_state=42, n_jobs=-1, max_features=\"sqrt\", bootstrap=True\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:16.98124\n",
      "[1]\tvalidation_0-rmse:16.20884\n",
      "[2]\tvalidation_0-rmse:15.90300\n",
      "[3]\tvalidation_0-rmse:15.47981\n",
      "[4]\tvalidation_0-rmse:15.36346\n",
      "[5]\tvalidation_0-rmse:15.16049\n",
      "[6]\tvalidation_0-rmse:15.16032\n",
      "[7]\tvalidation_0-rmse:15.09215\n",
      "[8]\tvalidation_0-rmse:14.69200\n",
      "[9]\tvalidation_0-rmse:14.52064\n",
      "[10]\tvalidation_0-rmse:14.52222\n",
      "[11]\tvalidation_0-rmse:14.48463\n",
      "[12]\tvalidation_0-rmse:14.45850\n",
      "[13]\tvalidation_0-rmse:14.34518\n",
      "[14]\tvalidation_0-rmse:14.19655\n",
      "[15]\tvalidation_0-rmse:14.18575\n",
      "[16]\tvalidation_0-rmse:14.11949\n",
      "[17]\tvalidation_0-rmse:14.10056\n",
      "[18]\tvalidation_0-rmse:13.97183\n",
      "[19]\tvalidation_0-rmse:13.93620\n",
      "[20]\tvalidation_0-rmse:13.94521\n",
      "[21]\tvalidation_0-rmse:13.90971\n",
      "[22]\tvalidation_0-rmse:13.86521\n",
      "[23]\tvalidation_0-rmse:13.83083\n",
      "[24]\tvalidation_0-rmse:13.80697\n",
      "[25]\tvalidation_0-rmse:13.70662\n",
      "[26]\tvalidation_0-rmse:13.70409\n",
      "[27]\tvalidation_0-rmse:13.68022\n",
      "[28]\tvalidation_0-rmse:13.68781\n",
      "[29]\tvalidation_0-rmse:13.31178\n",
      "[30]\tvalidation_0-rmse:13.27621\n",
      "[31]\tvalidation_0-rmse:13.21436\n",
      "[32]\tvalidation_0-rmse:13.19729\n",
      "[33]\tvalidation_0-rmse:13.18119\n",
      "[34]\tvalidation_0-rmse:13.28198\n",
      "[35]\tvalidation_0-rmse:13.29569\n",
      "[36]\tvalidation_0-rmse:13.00527\n",
      "[37]\tvalidation_0-rmse:13.00848\n",
      "[38]\tvalidation_0-rmse:12.99467\n",
      "[39]\tvalidation_0-rmse:13.00285\n",
      "[40]\tvalidation_0-rmse:13.01480\n",
      "[41]\tvalidation_0-rmse:12.93676\n",
      "[42]\tvalidation_0-rmse:12.89415\n",
      "[43]\tvalidation_0-rmse:12.82009\n",
      "[44]\tvalidation_0-rmse:12.81785\n",
      "[45]\tvalidation_0-rmse:12.67093\n",
      "[46]\tvalidation_0-rmse:12.67076\n",
      "[47]\tvalidation_0-rmse:12.60338\n",
      "[48]\tvalidation_0-rmse:12.60088\n",
      "[49]\tvalidation_0-rmse:12.58379\n",
      "[50]\tvalidation_0-rmse:12.57766\n",
      "[51]\tvalidation_0-rmse:12.54037\n",
      "[52]\tvalidation_0-rmse:12.54272\n",
      "[53]\tvalidation_0-rmse:12.59511\n",
      "[54]\tvalidation_0-rmse:12.49703\n",
      "[55]\tvalidation_0-rmse:12.51810\n",
      "[56]\tvalidation_0-rmse:12.51310\n",
      "[57]\tvalidation_0-rmse:12.57785\n",
      "[58]\tvalidation_0-rmse:12.56232\n",
      "[59]\tvalidation_0-rmse:12.54943\n",
      "[60]\tvalidation_0-rmse:12.57159\n",
      "[61]\tvalidation_0-rmse:12.57651\n",
      "[62]\tvalidation_0-rmse:12.57103\n",
      "[63]\tvalidation_0-rmse:12.56958\n",
      "[64]\tvalidation_0-rmse:12.55276\n",
      "[65]\tvalidation_0-rmse:12.55578\n",
      "[66]\tvalidation_0-rmse:12.52021\n",
      "[67]\tvalidation_0-rmse:12.47795\n",
      "[68]\tvalidation_0-rmse:12.47102\n",
      "[69]\tvalidation_0-rmse:12.42732\n",
      "[70]\tvalidation_0-rmse:12.44093\n",
      "[71]\tvalidation_0-rmse:12.43968\n",
      "[72]\tvalidation_0-rmse:12.43059\n",
      "[73]\tvalidation_0-rmse:12.42836\n",
      "[74]\tvalidation_0-rmse:12.43017\n",
      "[75]\tvalidation_0-rmse:12.44105\n",
      "[76]\tvalidation_0-rmse:12.38845\n",
      "[77]\tvalidation_0-rmse:12.37081\n",
      "[78]\tvalidation_0-rmse:12.44379\n",
      "[79]\tvalidation_0-rmse:12.43983\n",
      "[80]\tvalidation_0-rmse:12.42793\n",
      "[81]\tvalidation_0-rmse:12.29605\n",
      "[82]\tvalidation_0-rmse:12.29599\n",
      "[83]\tvalidation_0-rmse:12.31380\n",
      "[84]\tvalidation_0-rmse:12.31000\n",
      "[85]\tvalidation_0-rmse:12.30360\n",
      "[86]\tvalidation_0-rmse:12.28391\n",
      "[87]\tvalidation_0-rmse:12.30014\n",
      "[88]\tvalidation_0-rmse:12.31825\n",
      "[89]\tvalidation_0-rmse:12.32315\n",
      "[90]\tvalidation_0-rmse:12.32102\n",
      "[91]\tvalidation_0-rmse:12.31568\n",
      "[92]\tvalidation_0-rmse:12.31701\n",
      "[93]\tvalidation_0-rmse:12.26094\n",
      "[94]\tvalidation_0-rmse:12.25362\n",
      "[95]\tvalidation_0-rmse:12.24989\n",
      "[96]\tvalidation_0-rmse:12.25582\n",
      "[97]\tvalidation_0-rmse:12.29568\n",
      "[98]\tvalidation_0-rmse:12.22206\n",
      "[99]\tvalidation_0-rmse:12.21392\n",
      "[100]\tvalidation_0-rmse:12.19503\n",
      "[101]\tvalidation_0-rmse:12.18888\n",
      "[102]\tvalidation_0-rmse:12.18760\n",
      "[103]\tvalidation_0-rmse:12.18643\n",
      "[104]\tvalidation_0-rmse:12.18856\n",
      "[105]\tvalidation_0-rmse:12.21768\n",
      "[106]\tvalidation_0-rmse:12.15360\n",
      "[107]\tvalidation_0-rmse:12.15899\n",
      "[108]\tvalidation_0-rmse:12.14185\n",
      "[109]\tvalidation_0-rmse:12.13418\n",
      "[110]\tvalidation_0-rmse:12.20320\n",
      "[111]\tvalidation_0-rmse:12.20678\n",
      "[112]\tvalidation_0-rmse:12.20460\n",
      "[113]\tvalidation_0-rmse:12.19335\n",
      "[114]\tvalidation_0-rmse:12.19040\n",
      "[115]\tvalidation_0-rmse:12.51388\n",
      "[116]\tvalidation_0-rmse:12.50113\n",
      "[117]\tvalidation_0-rmse:12.50156\n",
      "[118]\tvalidation_0-rmse:12.51649\n",
      "[119]\tvalidation_0-rmse:12.53148\n",
      "[120]\tvalidation_0-rmse:12.48897\n",
      "[121]\tvalidation_0-rmse:12.49850\n",
      "[122]\tvalidation_0-rmse:12.49773\n",
      "[123]\tvalidation_0-rmse:12.47372\n",
      "[124]\tvalidation_0-rmse:12.59251\n",
      "[125]\tvalidation_0-rmse:12.60651\n",
      "[126]\tvalidation_0-rmse:12.61400\n",
      "[127]\tvalidation_0-rmse:12.61536\n",
      "[128]\tvalidation_0-rmse:12.61523\n",
      "[129]\tvalidation_0-rmse:12.61060\n",
      "[130]\tvalidation_0-rmse:12.63429\n",
      "[131]\tvalidation_0-rmse:12.62174\n",
      "[132]\tvalidation_0-rmse:12.57574\n",
      "[133]\tvalidation_0-rmse:12.57669\n",
      "[134]\tvalidation_0-rmse:12.74783\n",
      "[135]\tvalidation_0-rmse:12.74562\n",
      "[136]\tvalidation_0-rmse:12.66538\n",
      "[137]\tvalidation_0-rmse:12.66018\n",
      "[138]\tvalidation_0-rmse:12.66415\n",
      "[139]\tvalidation_0-rmse:12.55473\n",
      "[140]\tvalidation_0-rmse:12.52724\n",
      "[141]\tvalidation_0-rmse:12.52354\n",
      "[142]\tvalidation_0-rmse:12.50491\n",
      "[143]\tvalidation_0-rmse:12.50702\n",
      "[144]\tvalidation_0-rmse:12.50684\n",
      "[145]\tvalidation_0-rmse:12.51277\n",
      "[146]\tvalidation_0-rmse:12.48744\n",
      "[147]\tvalidation_0-rmse:12.49180\n",
      "[148]\tvalidation_0-rmse:12.49134\n",
      "[149]\tvalidation_0-rmse:12.49387\n",
      "[150]\tvalidation_0-rmse:12.50393\n",
      "[151]\tvalidation_0-rmse:12.51650\n",
      "[152]\tvalidation_0-rmse:12.51447\n",
      "[153]\tvalidation_0-rmse:12.50861\n",
      "[154]\tvalidation_0-rmse:12.51411\n",
      "[155]\tvalidation_0-rmse:12.53563\n",
      "[156]\tvalidation_0-rmse:12.60279\n",
      "[157]\tvalidation_0-rmse:12.60395\n",
      "[158]\tvalidation_0-rmse:12.60882\n",
      "[159]\tvalidation_0-rmse:12.60251\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[df.columns.difference([\"popularity\"])]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=40, random_state=42)\n",
    "\n",
    "# Initialize the XGBRegressor model\n",
    "model = XGBRegressor(\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    enable_categorical=True,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most important features:\n",
      "        feature  importance\n",
      "        romance    0.099651\n",
      "        iranian    0.056321\n",
      "      metalcore    0.044727\n",
      "          latin    0.043832\n",
      "           kids    0.040565\n",
      "          chill    0.036557\n",
      "     honky-tonk    0.035475\n",
      "      breakbeat    0.025325\n",
      "        j-dance    0.024959\n",
      "            sad    0.023523\n",
      "         techno    0.022933\n",
      "          anime    0.022562\n",
      "          party    0.019671\n",
      "          tango    0.019620\n",
      "          k-pop    0.018426\n",
      "       pop-film    0.018394\n",
      "       afrobeat    0.018330\n",
      "      grindcore    0.016354\n",
      "           soul    0.015925\n",
      " minimal-techno    0.015803\n",
      "      classical    0.013716\n",
      "            idm    0.011697\n",
      "          piano    0.011697\n",
      "    heavy-metal    0.010777\n",
      "          forro    0.010414\n",
      "        hip-hop    0.009985\n",
      "    alternative    0.009750\n",
      "        cluster    0.009698\n",
      "         latino    0.009627\n",
      " detroit-techno    0.009430\n",
      "  chicago-house    0.009295\n",
      "           rock    0.008702\n",
      "        ambient    0.008640\n",
      "          opera    0.008563\n",
      "          malay    0.007958\n",
      "        turkish    0.007410\n",
      "      power-pop    0.007160\n",
      "      sertanejo    0.007129\n",
      "          dance    0.006985\n",
      "            emo    0.006292\n",
      "           goth    0.005853\n",
      "       mandopop    0.005337\n",
      "            pop    0.005261\n",
      "       children    0.005168\n",
      "featured_tracks    0.005160\n",
      "          samba    0.005018\n",
      "         pagode    0.004709\n",
      "         reggae    0.004547\n",
      "         brazil    0.003946\n",
      "          sleep    0.003930\n"
     ]
    }
   ],
   "source": [
    "top_n = 50\n",
    "\n",
    "# Get feature importances and column names\n",
    "feature_importances = pd.DataFrame(\n",
    "    {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    ")\n",
    "\n",
    "# Sort by importance and get top_n\n",
    "top_features = feature_importances.sort_values(\"importance\", ascending=False).head(top_n)\n",
    "\n",
    "# Display results\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(top_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.5129150152206421\n",
      "MSE: 204.3378448486328\n",
      "RMSE: 14.294678688049316\n",
      "MAE: 9.804095268249512\n"
     ]
    }
   ],
   "source": [
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.23506581783294678\n",
      "MSE: 321.92266845703125\n",
      "RMSE: 17.942203521728516\n",
      "MAE: 14.01779556274414\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[df.columns.difference([\"popularity\"])]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the XGBRFRegressor model\n",
    "model = XGBRFRegressor(\n",
    "    tree_method=\"hist\", n_estimators=200, n_jobs=-1, random_state=42, enable_categorical=True\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most important features:\n",
      "        feature  importance\n",
      "        romance    0.116647\n",
      "          latin    0.089084\n",
      "        cluster    0.082707\n",
      "        iranian    0.055935\n",
      "           kids    0.053665\n",
      "     honky-tonk    0.047802\n",
      "      metalcore    0.045511\n",
      "       pop-film    0.042793\n",
      "    alternative    0.035005\n",
      "         techno    0.034517\n",
      "          dance    0.034318\n",
      "          chill    0.033964\n",
      "          opera    0.030056\n",
      "       afrobeat    0.029712\n",
      "           rock    0.026533\n",
      "   lead_streams    0.021848\n",
      "           funk    0.020846\n",
      " minimal-techno    0.019999\n",
      "      classical    0.018851\n",
      " detroit-techno    0.011958\n",
      "      grindcore    0.011233\n",
      "            pop    0.010132\n",
      "         reggae    0.009972\n",
      "  chicago-house    0.009672\n",
      "           soul    0.008708\n",
      "            idm    0.008527\n",
      "         disney    0.006789\n",
      "          indie    0.006618\n",
      "       children    0.006004\n",
      "        hip-hop    0.005899\n",
      "featured_tracks    0.004757\n",
      "        electro    0.004564\n",
      "        turkish    0.004553\n",
      "         j-rock    0.004393\n",
      "        country    0.003973\n",
      "          r-n-b    0.003924\n",
      "     psych-rock    0.003869\n",
      "         latino    0.003341\n",
      "           jazz    0.002885\n",
      "     songwriter    0.002653\n",
      "           folk    0.002633\n",
      "     duration_s    0.002149\n",
      "          disco    0.001920\n",
      "      reggaeton    0.001852\n",
      "        j-dance    0.001798\n",
      "         energy    0.001320\n",
      "    death-metal    0.001283\n",
      "      hard-rock    0.001278\n",
      "        valence    0.000877\n",
      "         german    0.000825\n"
     ]
    }
   ],
   "source": [
    "top_n = 50\n",
    "\n",
    "# Get feature importances and column names\n",
    "feature_importances = pd.DataFrame(\n",
    "    {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    ")\n",
    "\n",
    "# Sort by importance and get top_n\n",
    "top_features = feature_importances.sort_values(\"importance\", ascending=False).head(top_n)\n",
    "\n",
    "# Display results\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(top_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.49929462026689475\n",
      "MSE: 210.7219322145515\n",
      "RMSE: 14.516264402887938\n",
      "MAE: 10.169323500016093\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'features' is a list of feature column names\n",
    "X = df[top_features[\"feature\"].to_list()]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200, random_state=42, n_jobs=-1, max_features=\"sqrt\", bootstrap=True\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can skip stacked model maybe, its performance is only slightly above the RFRs.\n",
    "\n",
    "```md\n",
    "Stacked Model R^2: 0.537192088407299\n",
    "Stacked Model MSE: 194.77277721078033\n",
    "Stacked Model RMSE: 13.956101791359231\n",
    "Stacked Model MAE: 9.468840211962455\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the data\n",
    "# X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "#     df[top_features[\"feature\"].to_list()], df[\"popularity\"], test_size=0.3, random_state=42\n",
    "# )\n",
    "\n",
    "# # Base models\n",
    "# base_models = [\n",
    "#     (\"rf\", RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n",
    "#     (\"gb\", GradientBoostingRegressor(n_estimators=200, random_state=42)),\n",
    "#     (\"lr\", LinearRegression()),\n",
    "# ]\n",
    "\n",
    "# # Meta-model (Level 2 model)\n",
    "# meta_model = LinearRegression()\n",
    "\n",
    "# # Stacking model\n",
    "# stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "# stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Predictions and MSE\n",
    "# y_pred_stacked = stacked_model.predict(X_test_scaled)\n",
    "# mse_stacked = mean_squared_error(y_test, y_pred_stacked)\n",
    "# print(f\"Stacked Model MSE: {mse_stacked}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 = r2_score(y_test, y_pred_stacked)\n",
    "# mse = mean_squared_error(y_test, y_pred_stacked)\n",
    "# rmse = root_mean_squared_error(y_test, y_pred_stacked)\n",
    "# mae = mean_absolute_error(y_test, y_pred_stacked)\n",
    "\n",
    "# print(f\"Stacked Model R^2: {r2}\")\n",
    "# print(f\"Stacked Model MSE: {mse}\")\n",
    "# print(f\"Stacked Model RMSE: {rmse}\")\n",
    "# print(f\"Stacked Model MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
